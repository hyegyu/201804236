{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('카테고리_상품.csv', header=0, encoding='utf-8', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = reduce_mem_usage(df)\n",
    "df[\"review\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(df[df['review'].isnull()].index)\n",
    "df=df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "okt.morphs(df['review'].loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc'] = df['review'].str.replace(\"[^ㄱ-하-ㅣ가-힣]\", \" \")\n",
    "df['doc'].replace(\"\", np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 설정\n",
    "#-*- coding: utf-8 -*-\n",
    "f = open(\"korean_stopwords.txt\", 'r', encoding='utf-8')\n",
    "read = f.read()\n",
    "stop_words = read.split()\n",
    "\n",
    "name =\"상품명\"\n",
    "okt = Okt()\n",
    "st= okt.morphs(name)\n",
    "\n",
    "for i in range(len(stop_words)):\n",
    "    st.append(stop_words[i])\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa = [(df['score'] >= 4), (df['score'] == 3), (df['score'] <= 2)]\n",
    "bb = [1, 0, -1]\n",
    "df['rate'] = np.select(aa, bb, default='Not Specified')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean(dfdf):\n",
    "    okt = Okt()\n",
    "    dfdf=reduce_mem_usage(dfdf)\n",
    "    dfdf['word']=0\n",
    "    for i in range(len(dfdf)):\n",
    "        lists=[] \n",
    "        t_words = okt.nouns(dfdf['doc'].iloc[i])\n",
    "        for w in t_words:\n",
    "            if w not in st:\n",
    "                lists.append(w)\n",
    "        dfdf['word'].loc[i]=lists\n",
    "    return dfdf\n",
    "\n",
    "df_clean=clean(df)\n",
    "del df_clean[\"doc\"]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_clean[\"doc\"]\n",
    "df_train = df_clean[(df_clean['rate'] == '1') | (df_clean['rate'] == '-1')]\n",
    "df_test = df_clean[df_clean['rate']== '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(df_train)):\n",
    "    X_train.append(df_train['word'].iloc[i])\n",
    "\n",
    "X_test = []\n",
    "for i in range(len(df_test)):\n",
    "    X_test.append(df_test['word'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train 크기 :\", len(X_train))\n",
    "print(\"x_test 크기 :\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnt = len(tokenizer.word_index)\n",
    "rare_cnt = 0 \n",
    "total_freq = 0\n",
    "rare_freq = 0 \n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    if(value < 3):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "        \n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train) \n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(df_train['rate'])\n",
    "y_test = np.array(df_test['rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(X_train)\n",
    "X_test = pad_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test)):\n",
    "    score = (model.predict(X_test)[i]*100)\n",
    "    if(score >= 0.05):\n",
    "        df_test[\"rate\"].iloc[i] = '1'\n",
    "    if(score < 0.05):\n",
    "        df_test[\"rate\"].iloc[i] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"rate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([df_train,df_test])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "del df[\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=reduce_mem_usage(df)\n",
    "df1[\"rate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df1)):\n",
    "    if (df1[\"rate\"].iloc[i] ==  '1'):\n",
    "        df1[\"rate\"].iloc[i] =  '긍정'\n",
    "    if (df1[\"rate\"].iloc[i] ==  '-1'):\n",
    "        df1[\"rate\"].iloc[i] =  '부정'\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"rate\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
